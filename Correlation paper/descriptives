library(multcomp)
library(openxlsx)

IDmap <- read_excel("4. aRMT data.xlsx", sheet = "IDmap")

###  Descriptives  ###

demographics <- read_excel("2. Demographic Table.xlsx", sheet = "Demographics (R)") %>%
  select(1:27) %>%
  rename(p_id = P_ID) %>%
   rename(record_id = record_ID) %>%
  rename(date_of_assessment = `Date of assessment`) %>% 
  rename(tx_start = `Treatment start date`) %>%
  rename(tx_end = `Tx end`) %>%
  rename(tx_length = `Tx length (weeks)`) %>%
  rename(tx_start_days = `Tx start lag (days)`) %>%
  mutate(tx_start_days = as.numeric(tx_start_days)) %>%
  mutate(gender = as.factor(Gender) %>% 
           fct_recode("male" = "Male", "female" = "Female", "other" = "Neither")) %>% 
  mutate(ethnicity = as.factor(Ethnicity) %>% 
           fct_recode(
             "Asian / Asian British / Any other Asian background" = "Asian / Asian British: Indian", 
             "Asian / Asian British / Any other Asian background" = "Any other Asian background (Please describe)",
             "Black / African / Caribbean / Black British / Any other Black background" = "Black / African / Caribbean / Black British: Caribbean",
             "Black / African / Caribbean / Black British / Any other Black background" = "Any other Black / African / Caribbean background (Please describe)",
             "Black / African / Caribbean / Black British / Any other Black background" = "Black / African / Caribbean / Black British: African",
             "Middle Eastern" = "Middle Eastern",
             "Mixed/Multiple ethnic groups" = "Mixed/Multiple ethnic groups: White and Black Caribbean",
             "Mixed/Multiple ethnic groups" = "Any other Mixed / Multiple ethnic background (Please describe)",
             "White / White British / Any other White background" = "Any other White background (please describe)", 
             "White / White British / Any other White background" = "White: English / Welsh / Scottish / Northern Irish / British",
             "White / White British / Any other White background" = "White: Irish",
           )) %>% 
  mutate(education_level = as.factor(`What is your highest completed level of education?`) %>% 
           fct_recode(
             "Degree level" = "Degree level education / diploma (e.g. BSc, BA)",
             "Post-graduate Degree" = "Post-graduate Degree (e.g. MSc, MA, PhD)",                                                        
             "College level or equivalent" = "College level education or equivalent (A lever, NVQ, International Baccaleureate, BTEC nationals)",
             "Secondary education" = "Secondary education (GCSE, O Levels)"   
           )) %>% 
  mutate(employment = as.factor(`What is your main employment status?`)) %>% 
  select(-c(Gender, DoB, Ethnicity, `What is your main employment status?`, `What is your highest completed level of education?` ))
demographics$tx_start = convertToDate(demographics$tx_start, origin = "1900-01-01")
demographics$tx_end = convertToDate(demographics$tx_end, origin = "1900-01-01")

names(demographics)
demo <-demographics[c(1, 14,23,24,25,26)]      # demographic variables from script = descriptives.R !!!


## for PHQ analysis: can go back to PHQ_mixed models.R

#get baseline QIDS scores ------- 
# requires second_order_feature_extraction.R to be run

#add "date_of_assessment" to qids
qids_merge <- merge(qids, IDmap[,2:3], by.x=c("p_id"), by.y=c("participant_id"), all = TRUE, incomparables = T)

#create an event_name variable
baseline_qids<- qids_merge %>% 
  mutate(event_name = as.double(difftime(survey_date,date_assessment, units = "weeks")))
baseline_qids$event_name <- round(baseline_qids$event_name, digits = 0)

#create baseline df with only first 2 weeks
baseline_qids <-  baseline_qids[baseline_qids$event_name < 3, ] %>% 
  drop_na(p_id)

#BASELINE DATA FOR PARTICIPANTS  --  baseline_qids
#keep the lowest value per participant
baseline_qids <- baseline_qids %>% 
  group_by(p_id) %>% 
  slice_min(order_by = event_name) %>% 
  select(p_id, qids_total, date_assessment, event_name)

#merge demographic data with baseline_qids$qids_total
demo_total <- merge(demographics, baseline_qids, all = TRUE)
glimpse(demographics)


#### SIGNIFICANCE TESTING ON DEMOGRAPHICS ----
#IV: qids_total - numeric
#DV: Age, gender, ethnicity, education, employment

cor.test(demo_total$qids_total, demo_total$Age)
# r = 0.1214508, t = 0.78346, df = 41, p-value = 0.4379


aov <- aov(qids_total ~ employment,
               data = demo_total)
summary(aov)

#                  Df Sum Sq Mean Sq F value Pr(>F)
# gender           2   25.5   12.74     0.8  0.456
# ethnicity        4   79.7   19.92   1.299  0.288
# education_level  3   10.9   3.627   0.217  0.884
# employment       4  138.2   34.56   2.505 0.0582  (trend)


# Tukey HSD test:
post_test <- glht(aov,linfct = mcp(employment = "Tukey"))
summary(post_test)    #only trend between unemploymnt and paid employment
#                                            Estimate Std. Error t value Pr(>|t|)  
# Unemployment - Paid employment == 0        3.5309     1.3439   2.627   0.0768 .
plot(post_test)


sum(is.na(baseline_qids$p_id))
length(unique(baseline_qids$p_id))
length(unique(IDmap$participant_id))



#get baseline PHQ scores -----
# requires phq_mixed models.R to be run

#add "date_of_assessment" to phq
phq_merge <- merge(phq, IDmap[,2:3], by.x=c("p_id"), by.y=c("participant_id"), all = TRUE, incomparables = T)

#create an event_name variable
baseline_phq<- phq_merge %>% 
  mutate(event_name = as.double(difftime(survey_date,date_assessment, units = "weeks")))
baseline_phq$event_name <- round(baseline_phq$event_name, digits = 0)

#create baseline df with only first 2 weeks
baseline_phq <-  baseline_phq[baseline_phq$event_name < 4, ] %>% 
  drop_na(p_id)




#BASELINE DATA FOR PARTICIPANTS  --  baseline_phq
#keep the lowest value per participant
baseline_phq <- baseline_phq %>% 
  group_by(p_id) %>% 
  slice_min(order_by = event_name) %>% 
  select(p_id, total_phq, date_assessment, event_name)

#merge demographic data with baseline_phq$phq_total
demo_total <- merge(demographics, baseline_phq, all = TRUE)
glimpse(demo_total)


#### SIGNIFICANCE TESTING ON DEMOGRAPHICS ----
#IV: phq_total - numeric
#DV: Age, gender, ethnicity, education, employment

cor.test(demo_total$phq_total, demo_total$Age)
# r = 0.1214508, t = 0.78346, df = 41, p-value = 0.4379


aov <- aov(phq_total ~ employment,
           data = demo_total)
summary(aov)

#                  Df Sum Sq Mean Sq F value Pr(>F)
# gender           2   25.5   12.74     0.8  0.456
# ethnicity        4   79.7   19.92   1.299  0.288
# education_level  3   10.9   3.627   0.217  0.884
# employment       4  138.2   34.56   2.505 0.0582  (trend)


# Tukey HSD test:
post_test <- glht(aov,linfct = mcp(employment = "Tukey"))
summary(post_test)    #only trend between unemploymnt and paid employment
#                                            Estimate Std. Error t value Pr(>|t|)  
# Unemployment - Paid employment == 0        3.5309     1.3439   2.627   0.0768 .
plot(post_test)


sum(is.na(baseline_phq$p_id))
length(unique(baseline_phq$p_id))
length(unique(IDmap$participant_id))





# Histograms -----

hist(qids_passive$qids_total, breaks = 10,
     xlim=c(0, 25),
     ylim = c(0, 200),
     xlab = "Total QIDS")

hist(wsas$total_wsas, breaks = 15,
     xlim=c(0, 40),
     xlab = "Total WSAS")

# CORRELATIONs -------------

#correlation plot
names(d)

names(speech)
speech$Task.y[1]
 
cordf <- speech[, 5:33]   # define df

m <- cor(cordf, use = "complete.obs",   
         method = "spearman")  

mat <- cordf
# mat : is a matrix of data
# ... : further arguments to pass to the native R cor.test function
cor.mtest <- function(mat, ...) {
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p.mat<- matrix(NA, n, n)
  diag(p.mat) <- 0
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      tmp <- cor.test(mat[, i], mat[, j], ...)
      p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
    }
  }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(cordf)
head( round( p.mat[, 1:10], digits=4))

# Leave blank on non-significant coefficient
corrplot(m, type="upper", order="hclust",
         p.mat = p.mat, sig.level = 0.05, insig = "blank")



#cumulative frequency graph
h<-graph.freq(qids$qids_total,plot=FALSE)
points<-ogive.freq(h,col="red",frame=FALSE,
                   xlab="QIDS", ylab="Accumulated relative frequency", main="Cumulative frequency")




names(cordf)


#loop for correlation coeffs  - 

### USE inc_vars for variables with sufficient data

data <- cordf
outcome <- cordf$MISSING_RATE_mean_Activity 


for (i in 1:39) {
  corr <- cor.test(cordf$MISSING_RATE_mean_Activity, data[[i]])
  print(names(data)[i])
  print(corr$estimate)
  print(corr$p.value)
  # print(coef(summary(fit)))
  # print(summary(fit)$coefficients[2,"Pr(>|t|)"])
}

# print(round(confint(fit), digits = 6))

#extract correlations and p values
r <- cor(data$MISSING_RATE_mean_Activity , data[,names(data)], use = "complete.obs",
         method = "spearman")
r
p <- sapply(data[,names(data)], FUN=function(x, y) cor.test(x, y)$p.value, y=data$MISSING_RATE_mean_Activity )
p
ci <- sapply(data[,names(data)], FUN=function(x, y) cor.test(x, y)$conf.int, y=data$MISSING_RATE_mean_Activity )
ci

cors <- as.data.frame(rbind(r, p))
t(cors)
data_corrs <- rbind(cors, ci)
data_corrs <- as.data.frame(t(data_corrs))
data_corrs  <- tibble::rownames_to_column(data_corrs, "feature")

sig_cors <- as.data.frame(t(cors)) %>%
  rename(cor_coef = V1) %>%
  mutate(sig = ifelse(p < 0.01, "**",ifelse(p < 0.05, "*","_"))) %>%
  arrange(desc(cor_coef))

sig_cors[sig_cors$p < 0.05, ] 


## Pass it to corrplot
library(corrplot)
corrplot(as.matrix(cors), is.corr=FALSE, tl.srt=0)


#plot
scatter.smooth(x=data$sleep_onset_mean, y=data$data_total, main="plot")  # scatterplot


# correlation between QIDS an GAD and WSAS -----
# Run QIDS basic and GAD basic codes:

total_QIDS_GAD <- merge(qids_event, gad, all.x = T, by = c("p_id", "event_name"))

cor.test(total_QIDS_GAD$qids_total, total_QIDS_GAD$total_gad, use = "complete.obs")

# Pearson's product-moment correlation
# data:  total_QIDS_GAD$qids_total and total_QIDS_GAD$total_gad
# t = 18.152, df = 452, p-value < 2.2e-16

# 95% CI: 0.5927150  -  0.6995524
# cor = 0.6493259 
# r(452) = .649, p < 0.001

total_QIDS_GAD_WSAS <- merge(total_QIDS_GAD, wsas, all.x = T, by = c("p_id", "event_name"))

cor.test(total_QIDS_GAD_WSAS$qids_total, total_QIDS_GAD_WSAS$total_wsas, use = "complete.obs")

# Pearson's product-moment correlation
# data:  total_QIDS_GAD_WSAS$qids_total and total_QIDS_GAD_WSAS$total_wsas
# t = 34.445, df = 994, p-value < 2.2e-16

# 95% CI: 0.7079811  -  0.7647341
# cor =  0.7376578 
# r(994) = 0.738, p < 0.001


